{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37148b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "# Text Processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f959eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "MBTI = pd.read_csv(\"mbti_1.csv\")\n",
    "MBTI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba06ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MBTI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MBTI['posts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = MBTI.groupby(['type']).count()*50\n",
    "print(\"The Total Posts for every Personality Type\")\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(total, x=total.index, y='posts', labels={'posts': 'Number of posts', 'index': 'Personality types'},\n",
    "             title='Total posts for each personality type')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Personality types',\n",
    "    yaxis_title='Number of posts',\n",
    "    xaxis=dict(tickmode='linear'),  \n",
    "    yaxis=dict(title_text='Number of posts')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MBTI_DS_C = MBTI.copy()\n",
    "\n",
    "# Count Number words for each post of a user\n",
    "def var_row(row):\n",
    "    l = []\n",
    "    for i in row.split('|||'):\n",
    "        l.append(len(i.split()))\n",
    "    return np.var(l)\n",
    "\n",
    "# Count Number words per post for total 50 posts in whole row\n",
    "MBTI_DS_C['number of words in each post'] = MBTI_DS_C['posts'].apply(lambda x: len(x.split())/50)\n",
    "MBTI_DS_C['variance_word_count'] = MBTI_DS_C['posts'].apply(lambda x: var_row(x))\n",
    "\n",
    "fig = px.box(MBTI_DS_C, x='type', y='number of words in each post',\n",
    "             labels={'number of words in each post': 'Number of words per post', 'type': 'Personality types'},\n",
    "             title='Boxplot of Word count per post for each personality type')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Personality types',\n",
    "    yaxis_title='Number of words per post'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MBTI_DS_N = MBTI.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99808945",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "# Remove the stop words for speed \n",
    "useless_words = stopwords.words(\"english\")\n",
    "\n",
    "# Remove these from the posts\n",
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP','ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
    "unique_type_list = [x.lower() for x in unique_type_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the MBTI personality into 4 letters and binarizing it\n",
    "\n",
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # Transform MBTI to binary vector\n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "#Show result output for personality prediction\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to MBTI personality\n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n",
    "list_personality_bin = np.array([translate_personality(p) for p in MBTI_DS_N.type])\n",
    "print(\"Binarize MBTI list: \\n%s\" % list_personality_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_text(MBTI_DS_N, remove_stop_words=True, remove_mbti_profiles=True):\n",
    "    list_personality = []\n",
    "    list_posts = []\n",
    "    len_MBTI_DS_N = len(MBTI_DS_N)\n",
    "    i=0\n",
    "  \n",
    "    for row in MBTI_DS_N.iterrows():\n",
    "        #Remove and clean comments\n",
    "        posts = row[1].posts\n",
    "\n",
    "        #Remove url links \n",
    "        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
    "\n",
    "        #Remove Non-words - keep only words\n",
    "        temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
    "\n",
    "        # Remove spaces > 1\n",
    "        temp = re.sub(' +', ' ', temp).lower()\n",
    "\n",
    "        #Remove multiple letter repeating words\n",
    "        temp = re.sub(r'([a-z])\\1{2,}[\\s|\\w]*', '', temp)\n",
    "        \n",
    "        #Remove stop words\n",
    "        if remove_stop_words:\n",
    "            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in useless_words])\n",
    "        else:\n",
    "            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
    "          \n",
    "        #Remove MBTI personality words from posts\n",
    "        if remove_mbti_profiles:\n",
    "            for t in unique_type_list:\n",
    "                temp = temp.replace(t,\"\")\n",
    "\n",
    "        # transform mbti to binary vector\n",
    "        type_labelized = translate_personality(row[1].type) #or use lab_encoder.transform([row[1].type])[0]\n",
    "        list_personality.append(type_labelized)\n",
    "        # the cleaned data temp is passed here\n",
    "        list_posts.append(temp)\n",
    "\n",
    "    # returns the result\n",
    "    list_posts = np.array(list_posts)\n",
    "    list_personality = np.array(list_personality)\n",
    "    return list_posts, list_personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878dfc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_posts, list_personality  = pre_process_text(MBTI_DS_N, remove_stop_words=True, remove_mbti_profiles=True)\n",
    "\n",
    "print(\"Example :\")\n",
    "print(\"\\nPost before preprocessing:\\n\\n\", MBTI_DS_N.posts[0])\n",
    "print(\"\\nPost after preprocessing:\\n\\n\", list_posts[0])\n",
    "print(\"\\nMBTI before preprocessing:\\n\\n\", MBTI_DS_N.type[0])\n",
    "print(\"\\nMBTI after preprocessing:\\n\\n\", list_personality[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43345912",
   "metadata": {},
   "outputs": [],
   "source": [
    "nRow, nCol = list_personality.shape\n",
    "print(f'Number of posts = {nRow}  and No. of Personalities = {nCol} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b809cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the database posts to a matrix of token counts for the model\n",
    "cntizer = CountVectorizer(analyzer=\"word\", \n",
    "                             max_features=1000,  \n",
    "                             max_df=0.7,\n",
    "                             min_df=0.1) \n",
    "# the feature should be made of word n-gram \n",
    "\n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "print(\"Using CountVectorizer :\")\n",
    "X_cnt = cntizer.fit_transform(list_posts)\n",
    "\n",
    "#The enumerate object yields pairs containing a count and a value (useful for obtaining an indexed list)\n",
    "feature_names = list(enumerate(cntizer.get_feature_names()))\n",
    "print(\"10 feature names can be seen below\")\n",
    "print(feature_names[0:10])\n",
    "\n",
    "# For the Standardization or Feature Scaling Stage :-\n",
    "# Transform the count matrix to a normalized tf or tf-idf representation\n",
    "tfizer = TfidfTransformer()\n",
    "\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "print(\"\\nUsing Tf-idf :\")\n",
    "\n",
    "print(\"Now the dataset size is as below\")\n",
    "X_tfidf =  tfizer.fit_transform(X_cnt).toarray()\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_type = [ \"IE: Introversion (I) | Extroversion (E)\", \"NS: Intuition    (N) | Sensing      (S)\", \n",
    "                   \"FT: Feeling      (F) | Thinking     (T)\", \"JP: Judging      (J) | Perceiving   (P)\"  ]\n",
    "\n",
    "for l in range(len(personality_type)):\n",
    "    print(personality_type[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_tfidf\n",
    "# Logistic Regression for MBTI dataset\n",
    "# Individually training each mbti personlity type\n",
    "for l in range(len(personality_type)):\n",
    "#for l in range(1):\n",
    "    Y = list_personality[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=671)\n",
    "\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=671)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    logistic_regression = LogisticRegression()\n",
    "    param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear']\n",
    "    }\n",
    "  \n",
    "    grid_search = GridSearchCV(estimator=logistic_regression, param_grid=param_grid, cv=5, scoring='f1')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    # make predictions for test data\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))\n",
    "    print(\"%s Classification report for Test Data\" % (personality_type[l]))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
